{
  "name": "llama3",
  "version": "0.0.1-dev",
  "main": "llm.js",
  "type": "module",
  "bin": {
    "llama3-chat": "chat.js",
    "llama3-generate": "generate.js"
  },
  "author": "zcbenz",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/frost-beta/llama3.js.git"
  },
  "bugs": {
    "url": "https://github.com/frost-beta/llama3.js/issues"
  },
  "dependencies": {
    "@frost-beta/mlx": "0.0.14",
    "@lenml/tokenizer-llama3": "1.0.10",
    "@lenml/tokenizers": "1.0.9",
    "tick-promise": "1.0.0"
  },
  "packageManager": "yarn@1.22.22"
}
