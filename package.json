{
  "name": "llama3",
  "version": "0.0.1-dev",
  "main": "llm.js",
  "type": "module",
  "bin": {
    "llama3-chat": "chat.js"
  },
  "dependencies": {
    "@frost-beta/mlx": "0.0.5",
    "@lenml/tokenizers": "1.0.2"
  }
}
